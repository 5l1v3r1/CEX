// The GPL version 3 License (GPLv3)
// 
// Copyright (c) 2017 vtdev.com
// This file is part of the CEX Cryptographic library.
// 
// This program is free software : you can redistribute it and / or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
// 
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with this program. If not, see <http://www.gnu.org/licenses/>.

#ifndef CEX_POLYMATH_H
#define CEX_POLYMATH_H

#include "CexDomain.h"

#if defined(__AVX512__)
#	include "UInt512.h"
#elif defined(__AVX2__)
#	include "UInt256.h"
#elif defined(__AVX__)
#	include "UInt128.h"
#endif

NAMESPACE_UTILITY

/**
* \internal
*/

/// <summary>
/// Internal class used by RingLWE
/// </summary>
class PolyMath
{
public:

	template <class T>
	inline static T Abs(T &V)
	{
#if defined(__AVX__) || defined(__AVX2__) || defined(__AVX512__)
		return T::Abs(V);
#else
		T mask = V >> ((sizeof(T) * 8) - 1);
		return (V ^ mask) - mask;
#endif
	}

	template <typename Array, class T>
	inline static void Add(Array &R, const Array &A, const Array &B, int Q)
	{
		const T VN(5);

#if defined(__AVX__) || defined(__AVX2__) || defined(__AVX512__)
		const size_t ULVSZE = T::size() / sizeof(uint);
		std::array<uint, ULVSZE> tmpR;
		const T NQ(Q);
		T tmpA, tmpB;
#else
		const size_t ULVSZE = 1;
#endif

		for (size_t i = 0; i < R.size(); i += ULVSZE)
		{
#if defined(__AVX__) || defined(__AVX2__) || defined(__AVX512__)
#	if defined(__AVX512__)
			tmpA.Load(A[i + 15], A[i + 14], A[i + 13], A[i + 12], A[i + 11], A[i + 10], A[i + 9], A[i + 8], A[i + 7], A[i + 6], A[i + 5], A[i + 4], A[i + 3], A[i + 2], A[i + 1], A[i]);
			tmpB.Load(B[i + 15], B[i + 14], B[i + 13], B[i + 12], B[i + 11], B[i + 10], B[i + 9], B[i + 8], B[i + 7], B[i + 6], B[i + 5], B[i + 4], B[i + 3], B[i + 2], B[i + 1], B[i]);
#	elif defined(__AVX2__)
			tmpA.Load(A[i + 7], A[i + 6], A[i + 5], A[i + 4], A[i + 3], A[i + 2], A[i + 1], A[i]);
			tmpB.Load(B[i + 7], B[i + 6], B[i + 5], B[i + 4], B[i + 3], B[i + 2], B[i + 1], B[i]);
#	elif defined(__AVX__) 
			tmpA.Load(A[i + 3], A[i + 2], A[i + 1], A[i]);
			tmpB.Load(B[i + 3], B[i + 2], B[i + 1], B[i]);
#	endif

			T VF(tmpA + tmpB);
			T VU = (VF * VN) >> 16;
			VU *= NQ;
			VF -= VU;
			VF.Store(tmpR, 0);

			for (size_t j = 0; j < ULVSZE; ++j)
			{
				R[j + i] = static_cast<ushort>(tmpR[j]);
			}
#else
			T F = A[i] + B[i];
			uint U = static_cast<uint>(F * VN) >> 16;
			U *= Q;
			F -= U;
			R[i] = F;
#endif
		}
	}

	template <typename Array>
	inline static void BitReverse(Array &P)
	{
		uint r;
		ushort tmp;

		static const std::array<ushort, 1024> BitrevTable =
		{
			0x0U, 0x200U, 0x100U, 0x300U, 0x80U, 0x280U, 0x180U, 0x380U, 0x40U, 0x240U, 0x140U, 0x340U, 0xC0U, 0x2C0U, 0x1C0U, 0x3C0U,
			0x20U, 0x220U, 0x120U, 0x320U, 0xA0U, 0x2A0U, 0x1A0U, 0x3A0U, 0x60U, 0x260U, 0x160U, 0x360U, 0xE0U, 0x2E0U, 0x1E0U, 0x3E0U,
			0x10U, 0x210U, 0x110U, 0x310U, 0x90U, 0x290U, 0x190U, 0x390U, 0x50U, 0x250U, 0x150U, 0x350U, 0xD0U, 0x2D0U, 0x1D0U, 0x3D0U,
			0x30U, 0x230U, 0x130U, 0x330U, 0xB0U, 0x2B0U, 0x1B0U, 0x3B0U, 0x70U, 0x270U, 0x170U, 0x370U, 0xF0U, 0x2F0U, 0x1F0U, 0x3F0U,
			0x8U, 0x208U, 0x108U, 0x308U, 0x88U, 0x288U, 0x188U, 0x388U, 0x48U, 0x248U, 0x148U, 0x348U, 0xC8U, 0x2C8U, 0x1C8U, 0x3C8U,
			0x28U, 0x228U, 0x128U, 0x328U, 0xA8U, 0x2A8U, 0x1A8U, 0x3A8U, 0x68U, 0x268U, 0x168U, 0x368U, 0xE8U, 0x2E8U, 0x1E8U, 0x3E8U,
			0x18U, 0x218U, 0x118U, 0x318U, 0x98U, 0x298U, 0x198U, 0x398U, 0x58U, 0x258U, 0x158U, 0x358U, 0xD8U, 0x2D8U, 0x1D8U, 0x3D8U,
			0x38U, 0x238U, 0x138U, 0x338U, 0xB8U, 0x2B8U, 0x1B8U, 0x3B8U, 0x78U, 0x278U, 0x178U, 0x378U, 0xF8U, 0x2F8U, 0x1F8U, 0x3F8U,
			0x4U, 0x204U, 0x104U, 0x304U, 0x84U, 0x284U, 0x184U, 0x384U, 0x44U, 0x244U, 0x144U, 0x344U, 0xC4U, 0x2C4U, 0x1C4U, 0x3C4U,
			0x24U, 0x224U, 0x124U, 0x324U, 0xA4U, 0x2A4U, 0x1A4U, 0x3A4U, 0x64U, 0x264U, 0x164U, 0x364U, 0xE4U, 0x2E4U, 0x1E4U, 0x3E4U,
			0x14U, 0x214U, 0x114U, 0x314U, 0x94U, 0x294U, 0x194U, 0x394U, 0x54U, 0x254U, 0x154U, 0x354U, 0xD4U, 0x2D4U, 0x1D4U, 0x3D4U,
			0x34U, 0x234U, 0x134U, 0x334U, 0xB4U, 0x2B4U, 0x1B4U, 0x3B4U, 0x74U, 0x274U, 0x174U, 0x374U, 0xF4U, 0x2F4U, 0x1F4U, 0x3F4U,
			0xCU, 0x20CU, 0x10CU, 0x30CU, 0x8CU, 0x28CU, 0x18CU, 0x38CU, 0x4CU, 0x24CU, 0x14CU, 0x34CU, 0xCCU, 0x2CCU, 0x1CCU, 0x3CCU,
			0x2CU, 0x22CU, 0x12CU, 0x32CU, 0xACU, 0x2ACU, 0x1ACU, 0x3ACU, 0x6CU, 0x26CU, 0x16CU, 0x36CU, 0xECU, 0x2ECU, 0x1ECU, 0x3ECU,
			0x1CU, 0x21CU, 0x11CU, 0x31CU, 0x9CU, 0x29CU, 0x19CU, 0x39CU, 0x5CU, 0x25CU, 0x15CU, 0x35CU, 0xDCU, 0x2DCU, 0x1DCU, 0x3DCU,
			0x3CU, 0x23CU, 0x13CU, 0x33CU, 0xBCU, 0x2BCU, 0x1BCU, 0x3BCU, 0x7CU, 0x27CU, 0x17CU, 0x37CU, 0xFCU, 0x2FCU, 0x1FCU, 0x3FCU,
			0x2U, 0x202U, 0x102U, 0x302U, 0x82U, 0x282U, 0x182U, 0x382U, 0x42U, 0x242U, 0x142U, 0x342U, 0xC2U, 0x2C2U, 0x1C2U, 0x3C2U,
			0x22U, 0x222U, 0x122U, 0x322U, 0xA2U, 0x2A2U, 0x1A2U, 0x3A2U, 0x62U, 0x262U, 0x162U, 0x362U, 0xE2U, 0x2E2U, 0x1E2U, 0x3E2U,
			0x12U, 0x212U, 0x112U, 0x312U, 0x92U, 0x292U, 0x192U, 0x392U, 0x52U, 0x252U, 0x152U, 0x352U, 0xD2U, 0x2D2U, 0x1D2U, 0x3D2U,
			0x32U, 0x232U, 0x132U, 0x332U, 0xB2U, 0x2B2U, 0x1B2U, 0x3B2U, 0x72U, 0x272U, 0x172U, 0x372U, 0xF2U, 0x2F2U, 0x1F2U, 0x3F2U,
			0xAU, 0x20AU, 0x10AU, 0x30AU, 0x8AU, 0x28AU, 0x18AU, 0x38AU, 0x4AU, 0x24AU, 0x14AU, 0x34AU, 0xCAU, 0x2CAU, 0x1CAU, 0x3CAU,
			0x2AU, 0x22AU, 0x12AU, 0x32AU, 0xAAU, 0x2AAU, 0x1AAU, 0x3AAU, 0x6AU, 0x26AU, 0x16AU, 0x36AU, 0xEAU, 0x2EAU, 0x1EAU, 0x3EAU,
			0x1AU, 0x21AU, 0x11AU, 0x31AU, 0x9AU, 0x29AU, 0x19AU, 0x39AU, 0x5AU, 0x25AU, 0x15AU, 0x35AU, 0xDAU, 0x2DAU, 0x1DAU, 0x3DAU,
			0x3AU, 0x23AU, 0x13AU, 0x33AU, 0xBAU, 0x2BAU, 0x1BAU, 0x3BAU, 0x7AU, 0x27AU, 0x17AU, 0x37AU, 0xFAU, 0x2FAU, 0x1FAU, 0x3FAU,
			0x6U, 0x206U, 0x106U, 0x306U, 0x86U, 0x286U, 0x186U, 0x386U, 0x46U, 0x246U, 0x146U, 0x346U, 0xC6U, 0x2C6U, 0x1C6U, 0x3C6U,
			0x26U, 0x226U, 0x126U, 0x326U, 0xA6U, 0x2A6U, 0x1A6U, 0x3A6U, 0x66U, 0x266U, 0x166U, 0x366U, 0xE6U, 0x2E6U, 0x1E6U, 0x3E6U,
			0x16U, 0x216U, 0x116U, 0x316U, 0x96U, 0x296U, 0x196U, 0x396U, 0x56U, 0x256U, 0x156U, 0x356U, 0xD6U, 0x2D6U, 0x1D6U, 0x3D6U,
			0x36U, 0x236U, 0x136U, 0x336U, 0xB6U, 0x2B6U, 0x1B6U, 0x3B6U, 0x76U, 0x276U, 0x176U, 0x376U, 0xF6U, 0x2F6U, 0x1F6U, 0x3F6U,
			0xEU, 0x20EU, 0x10EU, 0x30EU, 0x8EU, 0x28EU, 0x18EU, 0x38EU, 0x4EU, 0x24EU, 0x14EU, 0x34EU, 0xCEU, 0x2CEU, 0x1CEU, 0x3CEU,
			0x2EU, 0x22EU, 0x12EU, 0x32EU, 0xAEU, 0x2AEU, 0x1AEU, 0x3AEU, 0x6EU, 0x26EU, 0x16EU, 0x36EU, 0xEEU, 0x2EEU, 0x1EEU, 0x3EEU,
			0x1EU, 0x21EU, 0x11EU, 0x31EU, 0x9EU, 0x29EU, 0x19EU, 0x39EU, 0x5EU, 0x25EU, 0x15EU, 0x35EU, 0xDEU, 0x2DEU, 0x1DEU, 0x3DEU,
			0x3EU, 0x23EU, 0x13EU, 0x33EU, 0xBEU, 0x2BEU, 0x1BEU, 0x3BEU, 0x7EU, 0x27EU, 0x17EU, 0x37EU, 0xFEU, 0x2FEU, 0x1FEU, 0x3FEU,
			0x1U, 0x201U, 0x101U, 0x301U, 0x81U, 0x281U, 0x181U, 0x381U, 0x41U, 0x241U, 0x141U, 0x341U, 0xC1U, 0x2C1U, 0x1C1U, 0x3C1U,
			0x21U, 0x221U, 0x121U, 0x321U, 0xA1U, 0x2A1U, 0x1A1U, 0x3A1U, 0x61U, 0x261U, 0x161U, 0x361U, 0xE1U, 0x2E1U, 0x1E1U, 0x3E1U,
			0x11U, 0x211U, 0x111U, 0x311U, 0x91U, 0x291U, 0x191U, 0x391U, 0x51U, 0x251U, 0x151U, 0x351U, 0xD1U, 0x2D1U, 0x1D1U, 0x3D1U,
			0x31U, 0x231U, 0x131U, 0x331U, 0xB1U, 0x2B1U, 0x1B1U, 0x3B1U, 0x71U, 0x271U, 0x171U, 0x371U, 0xF1U, 0x2F1U, 0x1F1U, 0x3F1U,
			0x9U, 0x209U, 0x109U, 0x309U, 0x89U, 0x289U, 0x189U, 0x389U, 0x49U, 0x249U, 0x149U, 0x349U, 0xC9U, 0x2C9U, 0x1C9U, 0x3C9U,
			0x29U, 0x229U, 0x129U, 0x329U, 0xA9U, 0x2A9U, 0x1A9U, 0x3A9U, 0x69U, 0x269U, 0x169U, 0x369U, 0xE9U, 0x2E9U, 0x1E9U, 0x3E9U,
			0x19U, 0x219U, 0x119U, 0x319U, 0x99U, 0x299U, 0x199U, 0x399U, 0x59U, 0x259U, 0x159U, 0x359U, 0xD9U, 0x2D9U, 0x1D9U, 0x3D9U,
			0x39U, 0x239U, 0x139U, 0x339U, 0xB9U, 0x2B9U, 0x1B9U, 0x3B9U, 0x79U, 0x279U, 0x179U, 0x379U, 0xF9U, 0x2F9U, 0x1F9U, 0x3F9U,
			0x5U, 0x205U, 0x105U, 0x305U, 0x85U, 0x285U, 0x185U, 0x385U, 0x45U, 0x245U, 0x145U, 0x345U, 0xC5U, 0x2C5U, 0x1C5U, 0x3C5U,
			0x25U, 0x225U, 0x125U, 0x325U, 0xA5U, 0x2A5U, 0x1A5U, 0x3A5U, 0x65U, 0x265U, 0x165U, 0x365U, 0xE5U, 0x2E5U, 0x1E5U, 0x3E5U,
			0x15U, 0x215U, 0x115U, 0x315U, 0x95U, 0x295U, 0x195U, 0x395U, 0x55U, 0x255U, 0x155U, 0x355U, 0xD5U, 0x2D5U, 0x1D5U, 0x3D5U,
			0x35U, 0x235U, 0x135U, 0x335U, 0xB5U, 0x2B5U, 0x1B5U, 0x3B5U, 0x75U, 0x275U, 0x175U, 0x375U, 0xF5U, 0x2F5U, 0x1F5U, 0x3F5U,
			0xDU, 0x20DU, 0x10DU, 0x30DU, 0x8DU, 0x28DU, 0x18DU, 0x38DU, 0x4DU, 0x24DU, 0x14DU, 0x34DU, 0xCDU, 0x2CDU, 0x1CDU, 0x3CDU,
			0x2DU, 0x22DU, 0x12DU, 0x32DU, 0xADU, 0x2ADU, 0x1ADU, 0x3ADU, 0x6DU, 0x26DU, 0x16DU, 0x36DU, 0xEDU, 0x2EDU, 0x1EDU, 0x3EDU,
			0x1DU, 0x21DU, 0x11DU, 0x31DU, 0x9DU, 0x29DU, 0x19DU, 0x39DU, 0x5DU, 0x25DU, 0x15DU, 0x35DU, 0xDDU, 0x2DDU, 0x1DDU, 0x3DDU,
			0x3DU, 0x23DU, 0x13DU, 0x33DU, 0xBDU, 0x2BDU, 0x1BDU, 0x3BDU, 0x7DU, 0x27DU, 0x17DU, 0x37DU, 0xFDU, 0x2FDU, 0x1FDU, 0x3FDU,
			0x3U, 0x203U, 0x103U, 0x303U, 0x83U, 0x283U, 0x183U, 0x383U, 0x43U, 0x243U, 0x143U, 0x343U, 0xC3U, 0x2C3U, 0x1C3U, 0x3C3U,
			0x23U, 0x223U, 0x123U, 0x323U, 0xA3U, 0x2A3U, 0x1A3U, 0x3A3U, 0x63U, 0x263U, 0x163U, 0x363U, 0xE3U, 0x2E3U, 0x1E3U, 0x3E3U,
			0x13U, 0x213U, 0x113U, 0x313U, 0x93U, 0x293U, 0x193U, 0x393U, 0x53U, 0x253U, 0x153U, 0x353U, 0xD3U, 0x2D3U, 0x1D3U, 0x3D3U,
			0x33U, 0x233U, 0x133U, 0x333U, 0xB3U, 0x2B3U, 0x1B3U, 0x3B3U, 0x73U, 0x273U, 0x173U, 0x373U, 0xF3U, 0x2F3U, 0x1F3U, 0x3F3U,
			0xBU, 0x20BU, 0x10BU, 0x30BU, 0x8BU, 0x28BU, 0x18BU, 0x38BU, 0x4BU, 0x24BU, 0x14BU, 0x34BU, 0xCBU, 0x2CBU, 0x1CBU, 0x3CBU,
			0x2BU, 0x22BU, 0x12BU, 0x32BU, 0xABU, 0x2ABU, 0x1ABU, 0x3ABU, 0x6BU, 0x26BU, 0x16BU, 0x36BU, 0xEBU, 0x2EBU, 0x1EBU, 0x3EBU,
			0x1BU, 0x21BU, 0x11BU, 0x31BU, 0x9BU, 0x29BU, 0x19BU, 0x39BU, 0x5BU, 0x25BU, 0x15BU, 0x35BU, 0xDBU, 0x2DBU, 0x1DBU, 0x3DBU,
			0x3BU, 0x23BU, 0x13BU, 0x33BU, 0xBBU, 0x2BBU, 0x1BBU, 0x3BBU, 0x7BU, 0x27BU, 0x17BU, 0x37BU, 0xFBU, 0x2FBU, 0x1FBU, 0x3FBU,
			0x7U, 0x207U, 0x107U, 0x307U, 0x87U, 0x287U, 0x187U, 0x387U, 0x47U, 0x247U, 0x147U, 0x347U, 0xC7U, 0x2C7U, 0x1C7U, 0x3C7U,
			0x27U, 0x227U, 0x127U, 0x327U, 0xA7U, 0x2A7U, 0x1A7U, 0x3A7U, 0x67U, 0x267U, 0x167U, 0x367U, 0xE7U, 0x2E7U, 0x1E7U, 0x3E7U,
			0x17U, 0x217U, 0x117U, 0x317U, 0x97U, 0x297U, 0x197U, 0x397U, 0x57U, 0x257U, 0x157U, 0x357U, 0xD7U, 0x2D7U, 0x1D7U, 0x3D7U,
			0x37U, 0x237U, 0x137U, 0x337U, 0xB7U, 0x2B7U, 0x1B7U, 0x3B7U, 0x77U, 0x277U, 0x177U, 0x377U, 0xF7U, 0x2F7U, 0x1F7U, 0x3F7U,
			0xFU, 0x20FU, 0x10FU, 0x30FU, 0x8FU, 0x28FU, 0x18FU, 0x38FU, 0x4FU, 0x24FU, 0x14FU, 0x34FU, 0xCFU, 0x2CFU, 0x1CFU, 0x3CFU,
			0x2FU, 0x22FU, 0x12FU, 0x32FU, 0xAFU, 0x2AFU, 0x1AFU, 0x3AFU, 0x6FU, 0x26FU, 0x16FU, 0x36FU, 0xEFU, 0x2EFU, 0x1EFU, 0x3EFU,
			0x1FU, 0x21FU, 0x11FU, 0x31FU, 0x9FU, 0x29FU, 0x19FU, 0x39FU, 0x5FU, 0x25FU, 0x15FU, 0x35FU, 0xDFU, 0x2DFU, 0x1DFU, 0x3DFU,
			0x3FU, 0x23FU, 0x13FU, 0x33FU, 0xBFU, 0x2BFU, 0x1BFU, 0x3BFU, 0x7FU, 0x27FU, 0x17FU, 0x37FU, 0xFFU, 0x2FFU, 0x1FFU, 0x3FFU
		};

		for (size_t i = 0; i < P.size(); ++i)
		{
			r = BitrevTable[i];
			if (i < r)
			{
				tmp = P[i];
				P[i] = P[r];
				P[r] = tmp;
			}
		}
	}

	template <typename Array, class T>
	inline static void Mul(Array &R, const Array &Factors, int Q, uint QInv, uint RLog)
	{
#if defined(__AVX__) || defined(__AVX2__) || defined(__AVX512__)
		const size_t ULVSZE = T::size() / sizeof(uint);
		std::array<uint, ULVSZE> tmpR;
		T tmpP, tmpF;
#else
		const size_t ULVSZE = 1;
#endif

		for (size_t i = 0; i < R.size(); i += ULVSZE)
		{
#if defined(__AVX__) || defined(__AVX2__) || defined(__AVX512__)
#	if defined(__AVX512__)
			tmpP.Load(R[i + 15], R[i + 14], R[i + 13], R[i + 12], R[i + 11], R[i + 10], R[i + 9], R[i + 8], R[i + 7], R[i + 6], R[i + 5], R[i + 4], R[i + 3], R[i + 2], R[i + 1], R[i]);
			tmpF.Load(Factors[i + 15], Factors[i + 14], Factors[i + 13], Factors[i + 12], Factors[i + 11], Factors[i + 10], Factors[i + 9], Factors[i + 8], Factors[i + 7], Factors[i + 6], Factors[i + 5], Factors[i + 4], Factors[i + 3], Factors[i + 2], Factors[i + 1], Factors[i]);
#	elif defined(__AVX2__)
			tmpP.Load(R[i + 7], R[i + 6], R[i + 5], R[i + 4], R[i + 3], R[i + 2], R[i + 1], R[i]);
			tmpF.Load(Factors[i + 7], Factors[i + 6], Factors[i + 5], Factors[i + 4], Factors[i + 3], Factors[i + 2], Factors[i + 1], Factors[i]);
#	elif defined(__AVX__) 
			tmpP.Load(R[i + 3], R[i + 2], R[i + 1], R[i]);
			tmpF.Load(Factors[i + 3], Factors[i + 2], Factors[i + 1], Factors[i]);
#	endif

			T a = tmpP * tmpF;
			T u = (a * T(QInv));
			u &= ((T::ONE() << RLog) - T::ONE());
			u *= T(Q);
			a += u;
			a >>= 18;
			a.Store(tmpR, 0);

			for (size_t j = 0; j < ULVSZE; ++j)
			{
				R[j + i] = static_cast<ushort>(tmpR[j]);
			}
#else
			T a = R[i] * Factors[i];
			T u = (a * QInv);
			u &= ((1 << RLog) - 1);
			u *= Q;
			a += u;
			R[i] = a >> 18;
#endif
		}
	}
};

NAMESPACE_UTILITYEND
#endif

